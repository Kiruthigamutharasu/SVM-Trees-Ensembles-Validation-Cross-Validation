# Assignment 16 – SVM, Trees, Ensembles, Validation & Cross-Validation

## Dataset
- **Name:** Titanic – train_and_test2.csv  
- **Source:** Kaggle  
- **Link:** https://www.kaggle.com/datasets/heptapod/titanic  
- **Type:** Supervised classification dataset with numerical features  
- **Target Variable:** 2urvived (0 = Not Survived, 1 = Survived)

## Libraries Used
- pandas  
- numpy  
- matplotlib  
- seaborn  
- scikit-learn  

## Tasks Implemented

### Part 1 – Advanced Supervised Algorithms
1. Support Vector Machine  
   - Linear Kernel  
   - RBF Kernel  
   - Accuracy comparison  

2. Decision Tree  
   - Low depth (underfitting)  
   - High depth (overfitting)  
   - Train vs test comparison  
   - Tree visualization  

### Part 2 – Validation Strategies
3. Train / Validation / Test split  
   - Parameter tuning using validation set  
   - Final evaluation on test set  

4. Cross Validation  
   - K-Fold (k=5)  
   - Average accuracy  
   - Comparison with single train-test split  

### Part 3 – Ensemble Learning
5. Bagging vs Boosting  
   - Conceptual explanation  
   - Bagging Classifier  
   - AdaBoost Classifier  
   - Performance comparison  

6. Random Forest  
   - Comparison with Decision Tree and Bagging  
   - Feature importance  

## How to Run
1. Install required libraries  
   pip install numpy pandas matplotlib seaborn scikit-learn

2. Keep dataset and notebook in same folder  
3. Run Assignment16.ipynb cell by cell
